# 1.google file system 
### Using hadoop file system can there can be more map reduce.
* it runs on a large number of commodity hardwards, and is able to replicate files among machines to tolerate and recover from failures
* it only handles extremely large files, usually at GB, or even TB and PB
* it only support file append, but not update

# 2.Mapreduce
### Mapreduce can be devided into three parts : MAP, SORT/SHUFFLE/MERGE, REDUCE
* Map and Reduce is programmable and provided by developers, and Shuffle is built-in. Map takes some inputs (usually a GFS/HDFS file), and breaks them into key-value pairs. Sort/Shuffle/Merge sorts outputs from all Map by key, and transport all records with the same key to the same place, guaranteed. Reduce does some other computations to records with the same key, and generates the final outcome by storing it in a new GFS/HDFS file.

# 3.Bigdata 
### an distribued system paradigm that realizes large scale parallel computation on top of huge amount of commodity hardware.
* Move computation to data, rather than transport data to where computation happens. This significantly reduces the network I/O patterns and keeps most of the I/O on the local disk or within the same rack.
* Put all input, intermediate output, and final output to a large scale, highly reliable, highly available, and highly scalable file system, a.k.a. GFS/HDFS, to have the file system take cares lots of concerns.
* Take advantage of an advanced resource management system. That system is able to automatically manage and monitor all work machines, assign resources to applications and jobs, recover from failure, and retry tasks.